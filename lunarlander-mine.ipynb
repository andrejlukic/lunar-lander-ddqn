{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736d835d-e4fd-4bf4-a1db-cd37976380c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:50:29.797837Z",
     "iopub.status.busy": "2023-02-04T23:50:29.797540Z",
     "iopub.status.idle": "2023-02-04T23:50:29.802000Z",
     "shell.execute_reply": "2023-02-04T23:50:29.800877Z",
     "shell.execute_reply.started": "2023-02-04T23:50:29.797817Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "# observation, info = env.reset(seed=42)\n",
    "# for _ in range(1000):\n",
    "#     action = env.action_space.sample()  # this is where you would insert your policy\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#     if terminated or truncated:\n",
    "#         observation, info = env.reset()\n",
    "#     clear_output(wait=True)\n",
    "#     plt.imshow( env.render() )\n",
    "#     plt.show()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7957e22-24f7-4c69-9b71-59b03eacc49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T16:48:55.417857Z",
     "iopub.status.busy": "2023-02-05T16:48:55.417425Z",
     "iopub.status.idle": "2023-02-05T16:49:01.641801Z",
     "shell.execute_reply": "2023-02-05T16:49:01.641006Z",
     "shell.execute_reply.started": "2023-02-05T16:48:55.417825Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 16:48:58.322749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import collections # For dequeue for the memory buffer\n",
    "\n",
    "\n",
    "class MemoryBuffer(object):\n",
    "    def __init__(self, max_size):\n",
    "        self.memory_size = max_size\n",
    "        self.trans_counter=0 # num of transitions in the memory\n",
    "                             # this count is required to delay learning\n",
    "                             # until the buffer is sensibly full\n",
    "        self.index=0         # current pointer in the buffer\n",
    "        self.states = np.zeros((self.memory_size, 8))       # list of states\n",
    "        self.new_states = np.zeros((self.memory_size, 8))   # list of new states\n",
    "        self.actions = np.zeros(self.memory_size, dtype=np.int8)  # list of actions (integer)\n",
    "        self.actions_oh = np.zeros((self.memory_size, 4), dtype=np.int8)  # list of one hot encoded actions\n",
    "        self.rewards = np.zeros(self.memory_size)  # list of rewards\n",
    "        self.terminals = np.zeros(self.memory_size, dtype=np.int8) # list of end of game signals\n",
    "    \n",
    "    def action_to_oh(self, action):\n",
    "        \"\"\" Get one hot representation of an action \"\"\"\n",
    "        \n",
    "        arr = np.zeros(4)\n",
    "        arr[action] = 1.0\n",
    "        return arr\n",
    "    \n",
    "    def ix(self):\n",
    "        \"\"\" Get current buffer index\"\"\"\n",
    "        return self.trans_counter % self.memory_size\n",
    "        \n",
    "    \n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        # print(\"Store transition, action=\", action)\n",
    "        self.states[self.ix()] = state\n",
    "        self.new_states[self.ix()] = new_state\n",
    "        self.rewards[self.ix()] = reward\n",
    "        self.terminals[self.ix()] = 1-int(done)\n",
    "        self.actions[self.ix()] = action\n",
    "        self.actions_oh[self.ix()] = self.action_to_oh(action)\n",
    "        # print(\"Stored\", self.action[self.ix()])\n",
    "        self.trans_counter += 1\n",
    "\n",
    "    def random_sample(self, batch_size):\n",
    "        assert self.trans_counter >= batch_size # start sampling when sufficiently full\n",
    "        choose_from = min(self.trans_counter, self.memory_size)\n",
    "        indices = np.random.choice(choose_from, batch_size) # number of transitions to sample\n",
    "        return self.states[indices], self.actions[indices], self.actions_oh[indices], \\\n",
    "               self.rewards[indices],self.new_states[indices], self.terminals[indices]\n",
    "    \n",
    "class SingleQAgent(object):\n",
    "    def __init__(self, lr, gamma, epsilon, batch_size,\n",
    "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
    "                 mem_size=1000000):\n",
    "        self.gamma = gamma # alpha = learn rate, gamma = discount\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec # decrement of epsilon for larger spaces\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = MemoryBuffer(mem_size)\n",
    "        nn = Sequential([\n",
    "                    Dense(256, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(256),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nn.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func = nn\n",
    "\n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        self.memory.save(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon: \n",
    "            # exploring: return a random action\n",
    "            return np.random.choice([i for i in range(4)])\n",
    "        else:\n",
    "            # greedy, returning best known action\n",
    "            sa = self.q_func.predict(state, verbose=0)\n",
    "            return np.argmax(sa)\n",
    "\n",
    "    def reduce_epsilon(self):\n",
    "        self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
    "                       self.epsilon_min else self.epsilon_min\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        if self.memory.trans_counter < self.batch_size: # wait before you start learning\n",
    "            return\n",
    "            \n",
    "        # 1. Choose a sample from past transitions:\n",
    "        states, actions, actions_oh, \\\n",
    "        rewards, new_states, terminals = self.memory.random_sample(self.batch_size)\n",
    "        \n",
    "        # 2. Compute predicted q value for the sample states\n",
    "        q = self.q_func.predict(states, verbose=0)\n",
    "        \n",
    "        # 3. Compute (using the same Q network) q value for the new states\n",
    "        q_next = self.q_func.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Improve the Q network\n",
    "        inx = np.arange(self.batch_size, dtype=np.int32)\n",
    "        q[inx, actions] = rewards + self.gamma*np.max(q_next, axis=1)*terminals\n",
    "        self.q_func.fit(states, q, verbose=0)\n",
    "        \n",
    "        # 5. Reduce the exploration rate\n",
    "        self.reduce_epsilon()\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.q_func.save(path)\n",
    "\n",
    "    def load_saved_model(self, path):\n",
    "        self.q_func = load_model(path)\n",
    "        \n",
    "class DoubleQAgent(object):\n",
    "    def __init__(self, lr, gamma, epsilon, batch_size,\n",
    "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
    "                 mem_size=1000000, replace_q_target = 100):\n",
    "        self.gamma = gamma # alpha = learn rate, gamma = discount\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec # decrement of epsilon for larger spaces\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = MemoryBuffer(mem_size)\n",
    "        self.replace_q_target = replace_q_target\n",
    "        nn = Sequential([\n",
    "                    Dense(128, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(128, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(128),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nn.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func = nn\n",
    "        \n",
    "        nnt = Sequential([\n",
    "                    Dense(128, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(128, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(128),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nnt.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func_target = nnt\n",
    "\n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        self.memory.save(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon: \n",
    "            # exploring: return a random action\n",
    "            return np.random.choice([i for i in range(4)])\n",
    "        else:\n",
    "            # greedy, returning best known action\n",
    "            sa = self.q_func.predict(state, verbose=0)\n",
    "            return np.argmax(sa)\n",
    "\n",
    "    def reduce_epsilon(self):\n",
    "        self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
    "                       self.epsilon_min else self.epsilon_min\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        if self.memory.trans_counter < self.batch_size: # wait before you start learning\n",
    "            return\n",
    "            \n",
    "        # 1. Choose a sample from past transitions:\n",
    "        states, actions, actions_oh, \\\n",
    "        rewards, new_states, terminals = self.memory.random_sample(self.batch_size)\n",
    "        \n",
    "        # 2. Compute predicted q value for the sample states\n",
    "        q = self.q_func.predict(states, verbose=0)\n",
    "        \n",
    "        # 3. Compute (using the same Q network) q value for the new states\n",
    "        q_next = self.q_func.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Update the Q target using the second Q network\n",
    "        q_target = self.q_func_target.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Improve the Q network\n",
    "        inx = np.arange(self.batch_size, dtype=np.int32)\n",
    "        q[inx, actions] = rewards + self.gamma*q_target[inx, np.argmax(q_next, axis=1).astype(int)]*terminals\n",
    "        self.q_func.fit(states, q, verbose=0)\n",
    "        \n",
    "        # 5. Reduce the exploration rate\n",
    "        self.reduce_epsilon()\n",
    "        \n",
    "        if self.memory.trans_counter % self.replace_q_target == 0: # wait before you start learning\n",
    "            self.q_func_target.set_weights(self.q_func.get_weights())\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.q_func.save(path)\n",
    "\n",
    "    def load_saved_model(self, path):\n",
    "        self.q_func = load_model(path)\n",
    "        if self.epsilon == 0.0:\n",
    "            self.q_func_target.set_weights(self.q_func.get_weights())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "addeff09-bc3d-4e80-84c3-b4ea5242caaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T11:14:45.501347Z",
     "iopub.status.busy": "2023-02-05T11:14:45.500789Z",
     "iopub.status.idle": "2023-02-05T11:14:45.503956Z",
     "shell.execute_reply": "2023-02-05T11:14:45.503456Z",
     "shell.execute_reply.started": "2023-02-05T11:14:45.501324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# from tensorflow.keras import Model, Sequential\n",
    "# from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from collections import deque\n",
    "# import time\n",
    "# # tf.disable_v2_behavior() # testing on tensorflow 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42f68d7-7e50-4aa8-b841-299c05e7f83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T11:14:47.049328Z",
     "iopub.status.busy": "2023-02-05T11:14:47.048782Z",
     "iopub.status.idle": "2023-02-05T11:14:47.054699Z",
     "shell.execute_reply": "2023-02-05T11:14:47.054199Z",
     "shell.execute_reply.started": "2023-02-05T11:14:47.049307Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotLearning(x, scores, epsilons, filename, lines=None):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, label=\"1\")\n",
    "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "    ax.plot(x, epsilons, color=\"C0\")\n",
    "    ax.set_xlabel(\"Game\", color=\"C0\")\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "        running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\n",
    "    #ax2.xaxis.tick_top()\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.yaxis.tick_right()\n",
    "    #ax2.set_xlabel('x label 2', color=\"C1\")\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\n",
    "    #ax2.xaxis.set_label_position('top')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    #ax2.tick_params(axis='x', colors=\"C1\")\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line)\n",
    "\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184d259-bfe0-4ad8-a43e-8bce502059c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T11:14:59.498102Z",
     "iopub.status.busy": "2023-02-05T11:14:59.497463Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -114.03  average score -114.03\n",
      "episode:  1 score: -165.54  average score -139.79\n",
      "episode:  2 score: -82.46  average score -120.68\n",
      "episode:  3 score: -108.29  average score -117.58\n",
      "episode:  4 score: -97.98  average score -113.66\n",
      "episode:  5 score: -298.06  average score -144.39\n",
      "episode:  6 score: -120.89  average score -141.04\n",
      "episode:  7 score: -75.55  average score -132.85\n",
      "episode:  8 score: -87.06  average score -127.76\n",
      "episode:  9 score: -214.97  average score -136.48\n",
      "episode:  10 score: -119.33  average score -134.92\n",
      "episode:  11 score: -186.78  average score -139.25\n",
      "episode:  12 score: -165.01  average score -141.23\n",
      "episode:  13 score: -301.88  average score -152.70\n",
      "episode:  14 score: -243.04  average score -158.73\n",
      "episode:  15 score: -87.50  average score -154.27\n",
      "episode:  16 score: -285.54  average score -161.99\n",
      "episode:  17 score: -355.82  average score -172.76\n",
      "episode:  18 score: -262.43  average score -177.48\n",
      "episode:  19 score: -165.83  average score -176.90\n",
      "episode:  20 score: -123.65  average score -174.36\n",
      "episode:  21 score: -148.08  average score -173.17\n",
      "episode:  22 score: -140.11  average score -171.73\n",
      "episode:  23 score: -254.37  average score -175.18\n",
      "episode:  24 score: -134.86  average score -173.56\n",
      "episode:  25 score: -130.59  average score -171.91\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json # for dumping debug data\n",
    "import time # for benchmarking \n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "LEARN_EVERY = 4\n",
    "def train_agent(atype='double', n_episodes=100, load_latest_model=False):\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    n_games = 2000\n",
    "    if atype == 'double':\n",
    "        agent = DoubleQAgent(gamma=0.99, epsilon=1.0, epsilon_dec=0.99996, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    elif atype == 'single':\n",
    "        agent = SingleQAgent(gamma=0.99, epsilon=1.0, epsilon_dec=0.99996, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    \n",
    "    if load_latest_model:\n",
    "        agent.load_saved_model('{}_dqn_model.h5'.format(atype))\n",
    "        print('Loaded most recent {} model.'.format(atype))\n",
    "        \n",
    "    scores = []\n",
    "    eps_history = []\n",
    "    for i in range(n_games):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        score = 0\n",
    "        state = env.reset()[0]\n",
    "        steps = 0\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            #print(action)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            if truncated:\n",
    "                print(\"Truncated game at {}\", steps)\n",
    "            score += reward\n",
    "            agent.save(state, action, reward, new_state, terminated or truncated)\n",
    "            state = new_state\n",
    "            if steps > 0 and steps % LEARN_EVERY == 0:\n",
    "                agent.learn()\n",
    "            if steps>0 and steps % 1000 == 0:\n",
    "                print(\"Steps\", steps)\n",
    "            steps += 1\n",
    "        eps_history.append(agent.epsilon)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        print('episode: ', i,'score: %.2f' % score,\n",
    "              ' average score %.2f' % avg_score)\n",
    "\n",
    "        if i % 10 == 0 and i > 0:\n",
    "            agent.save_model('{}_dqn_model.h5'.format(atype))\n",
    "            with open(\"{}_dqn_scores_{}.json\".format(atype, int(time.time())), \"w\") as fp:\n",
    "                json.dump(scores, fp)\n",
    "            with open(\"{}_eps_history_{}.json\".format(atype, int(time.time())), \"w\") as fp:\n",
    "                json.dump(eps_history, fp)\n",
    "\n",
    "        filename = 'lunarlander.png'\n",
    "\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plotLearning(x, scores, eps_history, filename)\n",
    "    \n",
    "train_agent(atype='double', n_episodes=100, load_latest_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596f509-6b4a-4ef5-b8f6-aae925b3d279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T16:49:01.643544Z",
     "iopub.status.busy": "2023-02-05T16:49:01.642990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model\n",
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def visualize_model(name, atype='single'):\n",
    "    env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "    agent = SingleQAgent(gamma=0.99, epsilon=0.0, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    agent.load_saved_model(name)\n",
    "    state, info = env.reset(seed=42)\n",
    "    for _ in range(5):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            if truncated:\n",
    "                print(\"Truncated game at {}\", steps)\n",
    "            state = new_state\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow( env.render() )\n",
    "            plt.show()\n",
    "        state = env.reset()[0]\n",
    "    env.close()\n",
    "\n",
    "visualize_model('double_dqn_model_epoch_50_fc256xfc256.h5', atype='double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2ec9c-b87a-4d60-a9e1-dd204bb9dc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
