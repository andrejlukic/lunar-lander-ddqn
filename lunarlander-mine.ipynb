{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736d835d-e4fd-4bf4-a1db-cd37976380c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:50:29.797837Z",
     "iopub.status.busy": "2023-02-04T23:50:29.797540Z",
     "iopub.status.idle": "2023-02-04T23:50:29.802000Z",
     "shell.execute_reply": "2023-02-04T23:50:29.800877Z",
     "shell.execute_reply.started": "2023-02-04T23:50:29.797817Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "# observation, info = env.reset(seed=42)\n",
    "# for _ in range(1000):\n",
    "#     action = env.action_space.sample()  # this is where you would insert your policy\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#     if terminated or truncated:\n",
    "#         observation, info = env.reset()\n",
    "#     clear_output(wait=True)\n",
    "#     plt.imshow( env.render() )\n",
    "#     plt.show()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7957e22-24f7-4c69-9b71-59b03eacc49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:58:49.149076Z",
     "iopub.status.busy": "2023-02-04T23:58:49.148829Z",
     "iopub.status.idle": "2023-02-04T23:58:49.169796Z",
     "shell.execute_reply": "2023-02-04T23:58:49.169286Z",
     "shell.execute_reply.started": "2023-02-04T23:58:49.149056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import collections # For dequeue for the memory buffer\n",
    "\n",
    "\n",
    "class MemoryBuffer(object):\n",
    "    def __init__(self, max_size):\n",
    "        self.memory_size = max_size\n",
    "        self.trans_counter=0 # num of transitions in the memory\n",
    "                             # this count is required to delay learning\n",
    "                             # until the buffer is sensibly full\n",
    "        self.index=0         # current pointer in the buffer\n",
    "        self.states = np.zeros((self.memory_size, 8))       # list of states\n",
    "        self.new_states = np.zeros((self.memory_size, 8))   # list of new states\n",
    "        self.actions = np.zeros(self.memory_size, dtype=np.int8)  # list of actions (integer)\n",
    "        self.actions_oh = np.zeros((self.memory_size, 4), dtype=np.int8)  # list of one hot encoded actions\n",
    "        self.rewards = np.zeros(self.memory_size)  # list of rewards\n",
    "        self.terminals = np.zeros(self.memory_size, dtype=np.int8) # list of end of game signals\n",
    "    \n",
    "    def action_to_oh(self, action):\n",
    "        \"\"\" Get one hot representation of an action \"\"\"\n",
    "        \n",
    "        arr = np.zeros(4)\n",
    "        arr[action] = 1.0\n",
    "        return arr\n",
    "    \n",
    "    def ix(self):\n",
    "        \"\"\" Get current buffer index\"\"\"\n",
    "        return self.trans_counter % self.memory_size\n",
    "        \n",
    "    \n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        # print(\"Store transition, action=\", action)\n",
    "        self.states[self.ix()] = state\n",
    "        self.new_states[self.ix()] = new_state\n",
    "        self.rewards[self.ix()] = reward\n",
    "        self.terminals[self.ix()] = 1-int(done)\n",
    "        self.actions[self.ix()] = action\n",
    "        self.actions_oh[self.ix()] = self.action_to_oh(action)\n",
    "        # print(\"Stored\", self.action[self.ix()])\n",
    "        self.trans_counter += 1\n",
    "\n",
    "    def random_sample(self, batch_size):\n",
    "        assert self.trans_counter >= batch_size # start sampling when sufficiently full\n",
    "        choose_from = min(self.trans_counter, self.memory_size)\n",
    "        indices = np.random.choice(choose_from, batch_size) # number of transitions to sample\n",
    "        return self.states[indices], self.actions[indices], self.actions_oh[indices], \\\n",
    "               self.rewards[indices],self.new_states[indices], self.terminals[indices]\n",
    "    \n",
    "class SingleQAgent(object):\n",
    "    def __init__(self, lr, gamma, epsilon, batch_size,\n",
    "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
    "                 mem_size=1000000):\n",
    "        self.gamma = gamma # alpha = learn rate, gamma = discount\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec # decrement of epsilon for larger spaces\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = MemoryBuffer(mem_size)\n",
    "        nn = Sequential([\n",
    "                    Dense(256, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(256),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nn.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func = nn\n",
    "\n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        self.memory.save(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon: \n",
    "            # exploring: return a random action\n",
    "            return np.random.choice([i for i in range(4)])\n",
    "        else:\n",
    "            # greedy, returning best known action\n",
    "            sa = self.q_func.predict(state, verbose=0)\n",
    "            return np.argmax(sa)\n",
    "\n",
    "    def reduce_epsilon(self):\n",
    "        self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
    "                       self.epsilon_min else self.epsilon_min\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        if self.memory.trans_counter < self.batch_size: # wait before you start learning\n",
    "            return\n",
    "            \n",
    "        # 1. Choose a sample from past transitions:\n",
    "        states, actions, actions_oh, \\\n",
    "        rewards, new_states, terminals = self.memory.random_sample(self.batch_size)\n",
    "        \n",
    "        # 2. Compute predicted q value for the sample states\n",
    "        q = self.q_func.predict(states, verbose=0)\n",
    "        \n",
    "        # 3. Compute (using the same Q network) q value for the new states\n",
    "        q_next = self.q_func.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Improve the Q network\n",
    "        inx = np.arange(self.batch_size, dtype=np.int32)\n",
    "        q[inx, actions] = rewards + self.gamma*np.max(q_next, axis=1)*terminals\n",
    "        self.q_func.fit(states, q, verbose=0)\n",
    "        \n",
    "        # 5. Reduce the exploration rate\n",
    "        self.reduce_epsilon()\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.q_func.save(path)\n",
    "\n",
    "    def load_saved_model(self, path):\n",
    "        self.q_func = load_model(path)\n",
    "        \n",
    "class DoubleQAgent(object):\n",
    "    def __init__(self, lr, gamma, epsilon, batch_size,\n",
    "                 epsilon_dec=0.996,  epsilon_end=0.01,\n",
    "                 mem_size=1000000, replace_q_target = 100):\n",
    "        self.gamma = gamma # alpha = learn rate, gamma = discount\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_dec # decrement of epsilon for larger spaces\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = MemoryBuffer(mem_size)\n",
    "        self.replace_q_target = replace_q_target\n",
    "        nn = Sequential([\n",
    "                    Dense(256, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(256),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nn.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func = nn\n",
    "        \n",
    "        nnt = Sequential([\n",
    "                    Dense(256, input_shape=(8,)),\n",
    "                    Activation('relu'),\n",
    "                    Dense(256),\n",
    "                    Activation('relu'),\n",
    "                    Dense(4)])\n",
    "        nnt.compile(optimizer=Adam(lr=lr), loss='mse')\n",
    "        self.q_func_target = nnt\n",
    "\n",
    "    def save(self, state, action, reward, new_state, done):\n",
    "        self.memory.save(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon: \n",
    "            # exploring: return a random action\n",
    "            return np.random.choice([i for i in range(4)])\n",
    "        else:\n",
    "            # greedy, returning best known action\n",
    "            sa = self.q_func.predict(state, verbose=0)\n",
    "            return np.argmax(sa)\n",
    "\n",
    "    def reduce_epsilon(self):\n",
    "        self.epsilon = self.epsilon*self.epsilon_dec if self.epsilon > \\\n",
    "                       self.epsilon_min else self.epsilon_min\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        if self.memory.trans_counter < self.batch_size: # wait before you start learning\n",
    "            return\n",
    "            \n",
    "        # 1. Choose a sample from past transitions:\n",
    "        states, actions, actions_oh, \\\n",
    "        rewards, new_states, terminals = self.memory.random_sample(self.batch_size)\n",
    "        \n",
    "        # 2. Compute predicted q value for the sample states\n",
    "        q = self.q_func.predict(states, verbose=0)\n",
    "        \n",
    "        # 3. Compute (using the same Q network) q value for the new states\n",
    "        q_next = self.q_func.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Update the Q target using the second Q network\n",
    "        q_target = self.q_func_target.predict(new_states, verbose=0)\n",
    "        \n",
    "        # 4. Improve the Q network\n",
    "        inx = np.arange(self.batch_size, dtype=np.int32)\n",
    "        q[inx, actions] = rewards + self.gamma*q_target[inx, np.argmax(q_next, axis=1).astype(int)]*terminals\n",
    "        self.q_func.fit(states, q, verbose=0)\n",
    "        \n",
    "        # 5. Reduce the exploration rate\n",
    "        self.reduce_epsilon()\n",
    "        \n",
    "        if self.memory.trans_counter % self.replace_q_target == 0: # wait before you start learning\n",
    "            self.q_func_target.set_weights(self.q_func.get_weights())\n",
    "\n",
    "    def save_model(self, path):\n",
    "        self.q_func.save(path)\n",
    "\n",
    "    def load_saved_model(self, path):\n",
    "        self.q_func = load_model(path)\n",
    "        if self.epsilon == 0.0:\n",
    "            self.q_func_target.set_weights(self.q_func.get_weights())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addeff09-bc3d-4e80-84c3-b4ea5242caaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:58:49.976445Z",
     "iopub.status.busy": "2023-02-04T23:58:49.975977Z",
     "iopub.status.idle": "2023-02-04T23:58:49.978939Z",
     "shell.execute_reply": "2023-02-04T23:58:49.978452Z",
     "shell.execute_reply.started": "2023-02-04T23:58:49.976425Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# from tensorflow.keras import Model, Sequential\n",
    "# from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from collections import deque\n",
    "# import time\n",
    "# # tf.disable_v2_behavior() # testing on tensorflow 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42f68d7-7e50-4aa8-b841-299c05e7f83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:58:50.500143Z",
     "iopub.status.busy": "2023-02-04T23:58:50.499536Z",
     "iopub.status.idle": "2023-02-04T23:58:50.505437Z",
     "shell.execute_reply": "2023-02-04T23:58:50.504956Z",
     "shell.execute_reply.started": "2023-02-04T23:58:50.500121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotLearning(x, scores, epsilons, filename, lines=None):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, label=\"1\")\n",
    "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "    ax.plot(x, epsilons, color=\"C0\")\n",
    "    ax.set_xlabel(\"Game\", color=\"C0\")\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "        running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\n",
    "    #ax2.xaxis.tick_top()\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.yaxis.tick_right()\n",
    "    #ax2.set_xlabel('x label 2', color=\"C1\")\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\n",
    "    #ax2.xaxis.set_label_position('top')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    #ax2.tick_params(axis='x', colors=\"C1\")\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line)\n",
    "\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9184d259-bfe0-4ad8-a43e-8bce502059c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T23:58:51.373269Z",
     "iopub.status.busy": "2023-02-04T23:58:51.372822Z",
     "iopub.status.idle": "2023-02-04T23:58:57.313380Z",
     "shell.execute_reply": "2023-02-04T23:58:57.312688Z",
     "shell.execute_reply.started": "2023-02-04T23:58:51.373249Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0 score: -259.69  average score -259.69\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_games)]\n\u001b[1;32m     61\u001b[0m     plotLearning(x, scores, eps_history, filename)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43matype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdouble\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_latest_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 39\u001b[0m, in \u001b[0;36mtrain_agent\u001b[0;34m(atype, n_episodes, load_latest_model)\u001b[0m\n\u001b[1;32m     37\u001b[0m agent\u001b[38;5;241m.\u001b[39msave(state, action, reward, new_state, terminated \u001b[38;5;129;01mor\u001b[39;00m truncated)\n\u001b[1;32m     38\u001b[0m state \u001b[38;5;241m=\u001b[39m new_state\n\u001b[0;32m---> 39\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m steps \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps)\n",
      "Cell \u001b[0;32mIn[15], line 192\u001b[0m, in \u001b[0;36mDoubleQAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce_epsilon()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mtrans_counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace_q_target \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# wait before you start learning\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_func_target\u001b[38;5;241m.\u001b[39mset_weights(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mget_weights())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json # for dumping debug data\n",
    "import time # for benchmarking \n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train_agent(atype='double', n_episodes=100, load_latest_model=False):\n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    n_games = 100\n",
    "    if atype == 'double':\n",
    "        agent = DoubleQAgent(gamma=0.99, epsilon=1.0, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    elif atype == 'single':\n",
    "        agent = SingleQAgent(gamma=0.99, epsilon=1.0, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    \n",
    "    if load_latest_model:\n",
    "        agent.load_saved_model('{}_dqn_model.h5'.format(atype))\n",
    "        print('Loaded most recent model.')\n",
    "        \n",
    "    scores = []\n",
    "    eps_history = []\n",
    "    for i in range(n_games):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        score = 0\n",
    "        state = env.reset()[0]\n",
    "        steps = 0\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            #print(action)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            if truncated:\n",
    "                print(\"Truncated game at {}\", steps)\n",
    "            score += reward\n",
    "            agent.save(state, action, reward, new_state, terminated or truncated)\n",
    "            state = new_state\n",
    "            agent.learn()\n",
    "            if steps>0 and steps % 1000 == 0:\n",
    "                print(\"Steps\", steps)\n",
    "            steps += 1\n",
    "        eps_history.append(agent.epsilon)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        avg_score = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        print('episode: ', i,'score: %.2f' % score,\n",
    "              ' average score %.2f' % avg_score)\n",
    "\n",
    "        if i % 10 == 0 and i > 0:\n",
    "            agent.save_model('{}_dqn_model.h5'.format(atype))\n",
    "            with open(\"{}_dqn_scores_{}.json\".format(atype, int(time.time())), \"w\") as fp:\n",
    "                json.dump(scores, fp)\n",
    "            with open(\"{}_eps_history_{}.json\".format(atype, int(time.time())), \"w\") as fp:\n",
    "                json.dump(eps_history, fp)\n",
    "\n",
    "        filename = 'lunarlander.png'\n",
    "\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plotLearning(x, scores, eps_history, filename)\n",
    "    \n",
    "train_agent(atype='double', n_episodes=100, load_latest_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e596f509-6b4a-4ef5-b8f6-aae925b3d279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T21:33:52.472641Z",
     "iopub.status.busy": "2023-02-04T21:33:52.472004Z",
     "iopub.status.idle": "2023-02-04T21:35:00.719476Z",
     "shell.execute_reply": "2023-02-04T21:35:00.718969Z",
     "shell.execute_reply.started": "2023-02-04T21:33:52.472619Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model\n",
    "import gymnasium as gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def visualize_model(atype='single', name):\n",
    "    env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "    agent = SingleQAgent(gamma=0.99, epsilon=0.0, lr=0.0005, mem_size=1000000, batch_size=64, epsilon_end=0.01)\n",
    "    agent.load_saved_model(name)\n",
    "    state, info = env.reset(seed=42)\n",
    "    for _ in range(5):\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.choose_action(state)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "            if truncated:\n",
    "                print(\"Truncated game at {}\", steps)\n",
    "            state = new_state\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow( env.render() )\n",
    "            plt.show()\n",
    "        state = env.reset()[0]\n",
    "    env.close()\n",
    "\n",
    "visualize_model('model_epoch_20_fc256xfc256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2ec9c-b87a-4d60-a9e1-dd204bb9dc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
